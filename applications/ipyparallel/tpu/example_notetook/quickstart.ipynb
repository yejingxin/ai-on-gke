{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/yejingxin/ai-on-gke/blob/ipp/applications/ipyparallel/tpu/example_notetook/quickstart.ipynb)\n",
        "[![Open On GitHub](https://img.shields.io/badge/Open-on%20GitHub-blue?logo=GitHub)](https://github.com/yejingxin/ai-on-gke/blob/ipp/applications/ipyparallel/tpu/example_notetook/quickstart.ipynb)\n",
        "\n",
        "# Quick Start Guide: Running Notebooks on Multi-host TPU\n",
        "This tutorial will guide you through initializing a notebook setup and running example cells on a multi-host TPU. This guide focuses on executing cells on an existing service. For information on setting up the service, please refer to this [user guide](https://github.com/yejingxin/ai-on-gke/blob/ipp/applications/ipyparallel/README.md)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install `ipyparallel`\n",
        "To interact with the cluster, we use IPython Parallel and cell magic. You can either have it pre-installed in the jupyter-notebook container image or install it using the following cell:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T9hZFyq7qxyA",
        "outputId": "d740771a-7926-4dea-b614-510ac504307f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ipyparallel\n",
            "  Downloading ipyparallel-8.8.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Requirement already satisfied: decorator in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (5.1.1)\n",
            "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (0.4)\n",
            "Requirement already satisfied: ipykernel>=4.4 in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (6.25.2)\n",
            "Requirement already satisfied: ipython>=4 in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (8.16.1)\n",
            "Requirement already satisfied: jupyter-client>=5 in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (8.4.0)\n",
            "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (5.9.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (2.8.2)\n",
            "Requirement already satisfied: pyzmq>=18 in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (25.1.1)\n",
            "Requirement already satisfied: tornado>=5.1 in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (6.3.3)\n",
            "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (4.66.1)\n",
            "Requirement already satisfied: traitlets>=4.3 in /opt/conda/lib/python3.11/site-packages (from ipyparallel) (5.11.2)\n",
            "Requirement already satisfied: comm>=0.1.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.4->ipyparallel) (0.1.4)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.4->ipyparallel) (1.8.0)\n",
            "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.4->ipyparallel) (5.4.0)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.4->ipyparallel) (0.1.6)\n",
            "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.4->ipyparallel) (1.5.8)\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from ipykernel>=4.4->ipyparallel) (23.2)\n",
            "Requirement already satisfied: backcall in /opt/conda/lib/python3.11/site-packages (from ipython>=4->ipyparallel) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.11/site-packages (from ipython>=4->ipyparallel) (0.19.1)\n",
            "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.11/site-packages (from ipython>=4->ipyparallel) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /opt/conda/lib/python3.11/site-packages (from ipython>=4->ipyparallel) (3.0.39)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /opt/conda/lib/python3.11/site-packages (from ipython>=4->ipyparallel) (2.16.1)\n",
            "Requirement already satisfied: stack-data in /opt/conda/lib/python3.11/site-packages (from ipython>=4->ipyparallel) (0.6.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.11/site-packages (from ipython>=4->ipyparallel) (4.8.0)\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.1->ipyparallel) (1.16.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/conda/lib/python3.11/site-packages (from jedi>=0.16->ipython>=4->ipyparallel) (0.8.3)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.11/site-packages (from jupyter-core!=5.0.*,>=4.12->ipykernel>=4.4->ipyparallel) (3.11.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.11/site-packages (from pexpect>4.3->ipython>=4->ipyparallel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.11/site-packages (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->ipython>=4->ipyparallel) (0.2.8)\n",
            "Requirement already satisfied: executing>=1.2.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=4->ipyparallel) (1.2.0)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=4->ipyparallel) (2.4.0)\n",
            "Requirement already satisfied: pure-eval in /opt/conda/lib/python3.11/site-packages (from stack-data->ipython>=4->ipyparallel) (0.2.2)\n",
            "Downloading ipyparallel-8.8.0-py3-none-any.whl (293 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.1/293.1 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ipyparallel\n",
            "Successfully installed ipyparallel-8.8.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ipyparallel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mount Filestore to Colab Enterprise Instance (Colab Enterprise Only)\n",
        "**Important: Non-Colab Enterprise users: Please skip this cell and proceed to the next section.**\n",
        "\n",
        "To mount the filestore to your Colab Enterprise instance, follow these steps:\n",
        "\n",
        "1. Run the following command:\n",
        "    ```\n",
        "    bash ipp_notebook.sh nfsmount\n",
        "    ```\n",
        "    This will generate the necessary mount command.\n",
        "\n",
        "2. Copy the generated command and paste it into the cell below.\n",
        "3. Execute the cell to mount the filestore.\n",
        "\n",
        "Example command (your actual command may differ):\n",
        "```\n",
        "!sudo apt-get install nfs-common && mkdir nfs && sudo mount -o nolock 10.195.89.130:/ipp nfs\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!sudo apt-get install nfs-common && mkdir nfs && sudo mount -o nolock <ip>:/<share_name> nfs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verify Client Config\n",
        "When the multi-host notebook service initializes, it automatically generates a client configuration file in the designated filestore folder. For both Colab and Jupyter Notebook environments, this filestore folder is pre-mounted in the GKE Jupyter Notebook pod for seamless access.\n",
        "\n",
        "To ensure proper setup, check the config file exist and accessible:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"ssh\": \"\",\n",
            "  \"interface\": \"tcp://10.56.0.132\",\n",
            "  \"registration\": 39167,\n",
            "  \"control\": 44173,\n",
            "  \"mux\": 41335,\n",
            "  \"task\": 56755,\n",
            "  \"task_scheme\": \"leastload\",\n",
            "  \"iopub\": 52367,\n",
            "  \"notification\": 43735,\n",
            "  \"broadcast\": 53291,\n",
            "  \"key\": \"566bf9eb-ea078ca7c904fde10cebb78f\",\n",
            "  \"curve_serverkey\": null,\n",
            "  \"location\": \"ipp-notebook-0\",\n",
            "  \"pack\": \"json\",\n",
            "  \"unpack\": \"json\",\n",
            "  \"signature_scheme\": \"hmac-sha256\"\n",
            "}"
          ]
        }
      ],
      "source": [
        "IPP_FILE_PATH = \"nfs/security/ipcontroller-client.json\"\n",
        "!cat {IPP_FILE_PATH}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to the TPU cluster\n",
        "Use this client config file to connect to different hosts in the TPU Cluster:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD1eEAw9xXv6",
        "outputId": "825bde45-6a90-4a08-f32b-e16a322c3e71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 3]\n",
            "Successfully established connection with 2 hosts\n"
          ]
        }
      ],
      "source": [
        "import ipyparallel as ipp\n",
        "rc = ipp.Client(IPP_FILE_PATH)\n",
        "print(rc.ids)\n",
        "if rc.ids:\n",
        " print(f'Successfully established connection with {len(rc.ids)} hosts')\n",
        "else:\n",
        " print(f'Failed to connect to {IPP_FILE_PATH}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##  Check Current Task Status\n",
        "A ready-to-use TPU cluster should have zero outstanding tasks, and all task queues should be marked as completed:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster task queue status: {'unassigned': 0, 0: {'queue': 0, 'completed': 1, 'tasks': 0}, 1: {'queue': 0, 'completed': 1, 'tasks': 0}, 2: {'queue': 0, 'completed': 0, 'tasks': 0}, 3: {'queue': 0, 'completed': 0, 'tasks': 0}}\n",
            "Current outstanding tasks: set()\n"
          ]
        }
      ],
      "source": [
        "print('Cluster task queue status:', rc.queue_status())\n",
        "print('Current outstanding tasks:', rc.outstanding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run a cell on different hosts\n",
        "We use the `%%px --block --group-outputs=engine` cell magic to execute code across hosts in blocking mode. For detailed instructions on cell magic, refer to the `ipyparallel` [documentation](https://ipyparallel.readthedocs.io/en/latest/tutorial/magics.html).  \n",
        "\n",
        "Example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "i1xjnqvOxbBQ",
        "outputId": "29e015e0-6981-467f-dd9d-de6b3d3854ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%px:   0%|          | 0/2 [00:03<?, ?tasks/s]"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[stdout:3] jax process 00 is running on ipp-notebook-0-2, local num of chips: 4, global num of chips: 8\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%px:  50%|█████     | 1/2 [00:03<00:00,  9.93tasks/s]"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[stdout:2] jax process 01 is running on ipp-notebook-0-1, local num of chips: 4, global num of chips: 8\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "%px: 100%|██████████| 2/2 [00:03<00:00,  1.61s/tasks]\n"
          ]
        }
      ],
      "source": [
        "%%px --block --group-outputs=engine\n",
        "import jax\n",
        "import socket\n",
        "print(f'jax process {jax.process_index():02d} is running on {socket.gethostname()}, \\\n",
        "local num of chips: {jax.local_device_count()}, global num of chips: {jax.device_count()}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This output demonstrates different JAX processes running on various hosts and displays the total number of chips within the TPU cluster in synchronous mode."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Clean Up\n",
        "Ensure all the tasks are completed and disconnect from the cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cluster task queue status: {'unassigned': 0, 0: {'queue': 0, 'completed': 1, 'tasks': 0}, 1: {'queue': 0, 'completed': 1, 'tasks': 0}, 2: {'queue': 0, 'completed': 1, 'tasks': 0}, 3: {'queue': 0, 'completed': 1, 'tasks': 0}}\n",
            "Current outstanding tasks: set()\n"
          ]
        }
      ],
      "source": [
        "print('Cluster task queue status:', rc.queue_status())\n",
        "print('Current outstanding tasks:', rc.outstanding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "rc.purge_everything()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "rc.shutdown()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Important**: The step above only disconnect the notebook from the cluster. The notebook service and cluster itself remain active. For complete resource cleanup, including shutting down the service and deleting cluster resources, please refer to the \"Clean Up\" section in the cluster [user guide](../../README.md). Proper cleanup ensures efficient resource management and prevents unnecessary costs."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
